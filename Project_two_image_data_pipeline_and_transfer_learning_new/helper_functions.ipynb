{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ed0f90-afd7-4c69-bbc6-95fa4d816deb",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15759947-e57e-4856-b1c3-d4e7e18a364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9148d16-87be-4101-afcc-114cca08ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219a2b6-4e88-40c4-8f73-36a6b9a11ebb",
   "metadata": {},
   "source": [
    "## Image Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbf190e-60ee-4da0-a2a8-67966fbf64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def view_random_images(X, y, classes_names, seed=42):\n",
    "    \"\"\"\n",
    "    Displays a grid of 1 sample image per class from the dataset, along with their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "    \n",
    "        X: array-like\n",
    "            The image dataset, typically a 4D array with shape (num_samples, height, width, channels).\n",
    "        y: array-like\n",
    "            The labels corresponding to each image in `X`, typically a 1D array with shape (num_samples,).\n",
    "        classes_names: list of str\n",
    "            A list of class names where each index corresponds to a class label in `y`.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "            Displays images in a grid with their respective labels beneath each image.\n",
    "\n",
    "    Notes:\n",
    "        - This function assumes that `y` contains integer class labels and that each class has at least one image.\n",
    "        - Images are displayed in a grid format, with each label shown below its corresponding image.\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = np.unique(y)\n",
    "    num_classes = len(labels)\n",
    "    num_cols = 5  # Set a fixed number of columns\n",
    "    num_rows = (num_classes + num_cols - 1) // num_cols  # Calculate rows to fit all classes\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    for i, label in enumerate(labels):\n",
    "        label_indices = [index for index, yi in enumerate(y) if yi == label]\n",
    "        rand_ind = random.choice(label_indices)  # Select a random index for the current label\n",
    "        \n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        plt.imshow(X[rand_ind])\n",
    "        plt.title(classes_names[label])\n",
    "        plt.axis('off')  # Hide axes for clarity\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e08355-2fab-45bf-9941-3b704bc638d1",
   "metadata": {},
   "source": [
    "## Plot loss and accuracy curves function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb72aaa5-008b-4d19-b8d6-87cc325976bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(model_history):\n",
    "    \"\"\"\n",
    "    This function generates two plots:\n",
    "    1. Training Loss vs. Validation Loss.\n",
    "    2. Training Accuracy vs. Validation Accuracy.\n",
    "\n",
    "    Args:\n",
    "        model_history (History): A Keras History object containing the training and validation metrics over epochs.\n",
    "\n",
    "    Returns:\n",
    "        None: The function plots the curves and does not return any value.\n",
    "    \"\"\"\n",
    "    # Losses\n",
    "    training_loss = model_history.history[\"loss\"]  # training loss across epochs\n",
    "    val_loss = model_history.history[\"val_loss\"]  # validation loss across epochs\n",
    "\n",
    "    # Accuracies\n",
    "    training_accuracy = model_history.history[\"accuracy\"]  # training accuracy across epochs\n",
    "    val_accuracy = model_history.history[\"val_accuracy\"]  # validation accuracy across epochs\n",
    "\n",
    "    number_of_epochs = len(training_loss)\n",
    "    epochs = range(number_of_epochs)\n",
    "\n",
    "    # Plot losses\n",
    "    plt.plot(epochs, training_loss, label='training_loss')\n",
    "    plt.plot(epochs, val_loss, label='validation_loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Training loss vs. Validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracies\n",
    "    plt.figure()  # a new figure for a separate plot\n",
    "    plt.plot(epochs, training_accuracy, label='training_accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='validation_accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Training accuracy vs. validation accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b56e1a-6e83-4307-89d9-cfd90532f8d9",
   "metadata": {},
   "source": [
    "## Model Evaluation results (for classification tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5e3ef2-db40-4af0-87e1-f6bb8d513c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "def model_evaluation(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Performs model evaluation by calculating model accuracy, precision, recall and f1 score for a multi-class classification model.\n",
    "\n",
    "    Args:\n",
    "        y_true (1D array): true labels (ground truth).\n",
    "        y_pred (1D array): predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of accuracy, precision, recall, and f1-score.\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # calculate precision, recall and f1-score\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    # reuslts in a dictionary\n",
    "    model_results = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1-score\": f1_score,\n",
    "    }\n",
    "    \n",
    "    return model_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479488ac-d9cf-4385-b5b2-09c5e30d5035",
   "metadata": {},
   "source": [
    "## LearningRateScheduler function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926c0810-fe96-4eb6-9927-576e29b18e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch_number, initial_lr=1e-3, drop_rate=0.5, epochs_drop=10):\n",
    "    \"\"\"\n",
    "    Adjust the learning rate based on the current epoch.\n",
    "    Note: This function is needed for the 'LearningRateScheduler' tf.keras callback\n",
    "\n",
    "    Parameters:\n",
    "        epoch_number (int): Current epoch number\n",
    "        initial_lr (float): Initial learning rate (default 1e-3)\n",
    "        drop_rate (float): Factor to drop the learning rate (default 0.5)\n",
    "        epochs_drop (int): Number of epochs before dropping the learning rate (default 10)\n",
    "\n",
    "    Returns:\n",
    "        lr (float): Updated learning rate\n",
    "    \"\"\"\n",
    "    # validate inputs\n",
    "    if not (0 < drop_rate <= 1):\n",
    "        raise ValueError(\"drop_rate must be between 0 and 1\")\n",
    "    if epochs_drop <= 0:\n",
    "        raise ValueError(\"epochs_drop must be a positive integer\")\n",
    "\n",
    "    # compute learning rate\n",
    "    lr = initial_lr * (drop_rate ** (epoch_number // epochs_drop))\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7443d7-fcf6-4a5c-86ed-162b03b9dadd",
   "metadata": {},
   "source": [
    "## check_image_shapes_and_ranges function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a634c2f1-457f-4488-9782-dc9d186c0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def check_image_shapes_and_ranges(data_dir):\n",
    "    shapes = []\n",
    "    pixel_ranges = []  # To store the min and max pixel values for each image\n",
    "\n",
    "    for class_ in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_)\n",
    "        if os.path.isdir(class_path):\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                image = Image.open(image_path)\n",
    "                shapes.append(image.size)\n",
    "\n",
    "                # Convert the image to a numpy array to find pixel range\n",
    "                image_array = np.array(image)\n",
    "                pixel_min = image_array.min()\n",
    "                pixel_max = image_array.max()\n",
    "                pixel_ranges.append((pixel_min, pixel_max))\n",
    "    \n",
    "    shapes_counter = Counter(shapes)\n",
    "    return shapes, shapes_counter, pixel_ranges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459e811-14ff-45e8-82da-47f641db18dc",
   "metadata": {},
   "source": [
    "## Image visualization function for images in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b5165b-fd79-453a-a958-bd3ea5bc6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot 1 random sample image per class with a fixed grid of 5 rows and 2 columns\n",
    "def view_random_images_data_dir(data_dir, classes):\n",
    "    \"\"\"\n",
    "    Display a grid of random sample images, one from each class in the dataset.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory containing class subdirectories.\n",
    "        classes (list): List of class names (subdirectory names) to display.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a 5x2 grid of images with class labels and numbers.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 20))  # Adjust figure size for a 5x2 grid\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        image_files = os.listdir(class_dir)\n",
    "        # Randomly select one image\n",
    "        img_file = random.choice(image_files)\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "        img = Image.open(img_path).resize((240, 240))  # Load and resize image using PIL\n",
    "        plt.subplot(5, 2, i + 1)  # 5 rows, 2 columns\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        # Add class name and number as the title\n",
    "        plt.title(f\"Class {i}: {class_name}\", fontsize=16, pad=8)  \n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.3)  # Adjust spacing\n",
    "    plt.suptitle(\"Random Sample Images from FoodVision-10 Dataset\", fontsize=24, y=0.92)  # Add a title\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff845e2e-29e9-4f80-a05d-de84b2998b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28357e4d-b7f6-43b7-a37d-4b13e93e6f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook converted to script: helper_functions.py\n"
     ]
    }
   ],
   "source": [
    "# import nbformat\n",
    "# from nbconvert import PythonExporter\n",
    "\n",
    "# # Load the notebook\n",
    "# input_file = 'helper_functions.ipynb'\n",
    "# output_file = 'helper_functions.py'\n",
    "\n",
    "# with open(input_file, 'r', encoding='utf-8') as f:\n",
    "#     notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "# # Convert notebook to script\n",
    "# python_exporter = PythonExporter()\n",
    "# script, _ = python_exporter.from_notebook_node(notebook)\n",
    "\n",
    "# # Save the script\n",
    "# with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#     f.write(script)\n",
    "\n",
    "# print(f\"Notebook converted to script: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ba01b6-ae89-40b7-931a-8cb434b6d344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/bin/jupyter-nbconvert\", line 7, in <module>\n",
      "    from nbconvert.nbconvertapp import main\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/nbconvert/nbconvertapp.py\", line 187, in <module>\n",
      "    class NbConvertApp(JupyterApp):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/nbconvert/nbconvertapp.py\", line 246, in NbConvertApp\n",
      "    Options include {get_export_names()}.\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/nbconvert/exporters/base.py\", line 151, in get_export_names\n",
      "    e = get_exporter(exporter_name)(config=config)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/nbconvert/exporters/base.py\", line 110, in get_exporter\n",
      "    exporter = items[0].load()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/metadata/__init__.py\", line 205, in load\n",
      "    module = import_module(match.group('module'))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py\", line 5, in <module>\n",
      "    from .collapsible_headings import ExporterCollapsibleHeadings\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py\", line 6, in <module>\n",
      "    from notebook.services.config import ConfigManager\n",
      "ModuleNotFoundError: No module named 'notebook.services'\n"
     ]
    }
   ],
   "source": [
    "# !jupyter nbconvert --to script helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa449e-cc21-4bd2-b8b9-abed59fd8a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e5ed9-05a7-43ad-aba1-e7d4e15eea4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
